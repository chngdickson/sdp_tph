{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "Reading pcd file...\n",
      "Reading PCD file successful, Generating stuff\n"
     ]
    }
   ],
   "source": [
    "from utility.pcd2img import pcd2img_np\n",
    "from trained_model.yolo_detect import Detect\n",
    "from utility.get_coords import scale_pred_to_xy_point_cloud, draw_coord_on_img, scale_coord, get_strides\n",
    "from utility.generate_tree import get_tree_many_from_coords, get_h_from_each_tree_slice\n",
    "from utility.csf_py import csf_py\n",
    "\n",
    "# Standard Libraries\n",
    "import os\n",
    "import cv2\n",
    "import yaml\n",
    "import open3d as o3d\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "with open(\"config/config.yaml\", 'r') as ymlfile:\n",
    "    yml_data = yaml.load(ymlfile, Loader = yaml.FullLoader)\n",
    "\n",
    "# Input Folder Location\n",
    "curr_dir = os.getcwd()\n",
    "folder_loc = yml_data[\"dataset\"][\"folder_location\"]\n",
    "pcd_filename = yml_data[\"dataset\"][\"pcd\"][\"file_name\"] + yml_data[\"dataset\"][\"pcd\"][\"file_type\"]\n",
    "\n",
    "# Output Folder Location\n",
    "output_folder = os.getcwd() + yml_data[\"output\"][\"folder_location\"] +\"/\"+ yml_data[\"dataset\"][\"pcd\"][\"file_name\"] +\"/\"\n",
    "topViewOut = output_folder + yml_data[\"output\"][\"topView\"][\"folder_location\"]\n",
    "sideViewOut = output_folder + yml_data[\"output\"][\"sideView\"][\"folder_location\"]\n",
    "csvOut = output_folder + yml_data[\"dataset\"][\"pcd\"][\"file_name\"] +\".csv\"\n",
    "pcd_name = yml_data[\"dataset\"][\"pcd\"][\"file_name\"]\n",
    "\n",
    "# Read pcd\n",
    "print(\"Reading pcd file...\")\n",
    "pcd = o3d.io.read_point_cloud(folder_loc+pcd_filename)\n",
    "\n",
    "assert len(pcd.points) >= 1, f\"Failed to Read PCD [{pcd_filename}], it's Empty\"\n",
    "\n",
    "print(\"Reading PCD file successful, Generating stuff\")\n",
    "for path in [output_folder, topViewOut, sideViewOut]:\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. CSF and Rasterize Top View\n",
    "1. Load Yolov5 Model\n",
    "2. CSF and Rasterize to image Based on set Params\n",
    "    - Relief : SloopSmooth = True, res = Medium(7.0), Threshold = Med(1.0), rigidness = 3\n",
    "    - Steep Slope: SloopSmooth=True, res = High(15.0), Threshold = High(2.0), rigidness = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2022-05-12 13:10:17,110 - torch_utils - YOLOv5 ðŸš€ v6.1-82-g71621df torch 1.11.0+cu102 CUDA:0 (NVIDIA GeForce GTX 1070, 8105MiB)\n",
      "\n",
      "INFO - 2022-05-12 13:10:21,020 - yolo - Fusing layers... \n",
      "INFO - 2022-05-12 13:10:21,239 - torch_utils - Model summary: 290 layers, 20852934 parameters, 0 gradients, 47.9 GFLOPs\n",
      "INFO - 2022-05-12 13:10:21,243 - common - Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_size:  [640, 640]\n",
      "Device :  cuda\n",
      "[0] Configuring terrain...\n",
      "[0] Configuring cloth...\n",
      "[0]  - width: 19 height: 19\n",
      "[0] Rasterizing...\n",
      "[0] Simulating...\n",
      "[0]  - post handle...\n"
     ]
    }
   ],
   "source": [
    "# Yaml Params\n",
    "topViewStepsize = yml_data[\"yolov5\"][\"topView\"][\"stepsize\"]\n",
    "top_view_model_pth = yml_data[\"yolov5\"][\"topView\"][\"model_pth\"]\n",
    "yolov5_folder_pth = yml_data[\"yolov5\"][\"yolov5_pth\"]\n",
    "ideal_img_size = yml_data[\"yolov5\"][\"topView\"][\"imgSize\"]\n",
    "\n",
    "# 1. Generate Top View Yolov5 Model\n",
    "topViewModel = Detect(yolov5_folder_pth, top_view_model_pth, img_size=ideal_img_size)\n",
    "\n",
    "grd, non_grd = csf_py(\n",
    "    pcd, \n",
    "    return_non_ground = \"both\", \n",
    "    bsloopSmooth = True, \n",
    "    cloth_res = 15.0, \n",
    "    threshold= 2.0, \n",
    "    rigidness=1\n",
    ")\n",
    "# 2. Create img from CSF\n",
    "non_ground_img = pcd2img_np(non_grd,\"z\",topViewStepsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Split Large Image into Multiple Images\n",
    "The reason for this step is to make sure the Images are within the scale of Yolov5 Top View Model. To get the ideal and maximum effectiveness for Tree Height detection\n",
    "1. calculate spacing, then use linspace for even spacing\n",
    "2. Split the Images\n",
    "    - For each Split image, run inference with yolov5\n",
    "    - Merge and scale the Coordinates of each image into one list\n",
    "4. Scale 2D coordinates to 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Coordinates from Top View\n",
    "coordinates = []\n",
    "\n",
    "# 1. Calculate spacing for image splitting\n",
    "h_s, w_s = get_strides(non_ground_img.shape, ideal_img_size)\n",
    "h_arr, h_incre = np.linspace(0, non_ground_img.shape[0], h_s+1, retstep=True)\n",
    "w_arr, w_incre = np.linspace(0, non_ground_img.shape[1], w_s+1, retstep=True)\n",
    "\n",
    "# 2. Split images \n",
    "for i, h in enumerate(h_arr[:-1]):\n",
    "    for j, w in enumerate(w_arr[:-1]):\n",
    "        img = non_ground_img[int(round(h)):int(round(h+h_incre)), int(round(w)):int(round(w+w_incre))]\n",
    "        preds = topViewModel.predict(\n",
    "            img,\n",
    "            convert_to_gray=False,\n",
    "            confi_thres = 0.134,\n",
    "            iou_thres = 0.02\n",
    "            )\n",
    "        coordinates.extend(scale_pred_to_xy_point_cloud(preds, 1, w, h))\n",
    "        del img, preds\n",
    "\n",
    "# 2c Visualization Purpose\n",
    "img_with_coord = draw_coord_on_img(non_ground_img, np.asarray(coordinates), circle_size=10)\n",
    "cv2.imwrite(f\"{topViewOut}/{pcd_name}_coor.png\", img_with_coord)\n",
    "\n",
    "# 3. Scale 2D to 3D\n",
    "xmin, ymin, zmin = non_grd.get_min_bound()\n",
    "xmax, ymax, zmax = non_grd.get_max_bound()\n",
    "range_x, range_y, range_z = xmax-xmin, ymax-ymin, zmax-zmin\n",
    "\n",
    "height, width = non_ground_img.shape\n",
    "coordinates = scale_coord(\n",
    "    np.asarray(coordinates), \n",
    "    scale=(range_x/width, range_y/height), \n",
    "    offset=(xmin,-ymax)\n",
    "    )\n",
    "\n",
    "# 4. Clear unused memory\n",
    "del topViewModel\n",
    "del non_grd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Generate Height Map from Coordinates (x,y)\n",
    "1. Initialize Yolov5 Side View Model\n",
    "2. Crop Each Tree From specified Coordinates\n",
    "    - Slice the Point cloud in X and Y axis\n",
    "        - Run Yolov5 Inference on each Slice to find Height\n",
    "        - Store Height on Each Slice\n",
    "    - Current Algo: Get the maximum Height of all slice\n",
    "    - Store [x,y and height] in coords_hs list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2022-05-12 13:11:02,963 - torch_utils - YOLOv5 ðŸš€ v6.1-82-g71621df torch 1.11.0+cu102 CUDA:0 (NVIDIA GeForce GTX 1070, 8105MiB)\n",
      "\n",
      "INFO - 2022-05-12 13:11:04,493 - yolo - Fusing layers... \n",
      "INFO - 2022-05-12 13:11:04,707 - torch_utils - Model summary: 290 layers, 20856975 parameters, 0 gradients, 48.0 GFLOPs\n",
      "INFO - 2022-05-12 13:11:04,711 - common - Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_size:  [320, 768]\n",
      "Device :  cuda\n"
     ]
    }
   ],
   "source": [
    "# Yaml Params\n",
    "side_view_model_pth = yml_data[\"yolov5\"][\"sideView\"][\"model_pth\"]\n",
    "side_view_step_size = yml_data[\"yolov5\"][\"sideView\"][\"stepsize\"]\n",
    "side_view_img_size = tuple(yml_data[\"yolov5\"][\"sideView\"][\"imgSize\"])\n",
    "min_points_per_tree = yml_data[\"yolov5\"][\"sideView\"][\"minNoPoints\"]\n",
    "\n",
    "# Init SideViewYolo Model\n",
    "sideViewModel = Detect(yolov5_folder_pth, side_view_model_pth, img_size=side_view_img_size)\n",
    "coords_hs = []\n",
    "ex_w, ex_h = (dim*side_view_step_size for dim in side_view_img_size)\n",
    "values = get_tree_many_from_coords(pcd, grd, coordinates,expand=[ex_w,ex_w,ex_h])\n",
    "\n",
    "# Visualization Purposes\n",
    "# trees = values[:,0].tolist()\n",
    "# bBoxes = values[:,1].tolist()\n",
    "# o3d.visualization.draw_geometries(bBoxes+trees+[pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358\n"
     ]
    }
   ],
   "source": [
    "# Generate Height from each Tree\n",
    "# 1. Filter out Trees that are below a threshold of points\n",
    "# 2. Generate Image for each point cloud\n",
    "# 3. Calculate Height of Each tree from Image\n",
    "# 4. Scale the value\n",
    "# 5. Clear memory\n",
    "print(len(values))\n",
    "\n",
    "for index, value in enumerate(values):\n",
    "    tree, _, x,y = value\n",
    "    h = get_h_from_each_tree_slice(\n",
    "        tree = tree,\n",
    "        model = sideViewModel,\n",
    "        img_size = side_view_img_size, \n",
    "        stepsize = side_view_step_size,\n",
    "        img_dir = f\"{sideViewOut}/{pcd_name}_{index}_\",\n",
    "        gen_img = True,\n",
    "        img_with_h = False,\n",
    "        min_no_points = min_points_per_tree\n",
    "        )\n",
    "    coords_hs.append((x,y,h,index)) if h > 0 else None\n",
    "\n",
    "\n",
    "del sideViewModel, pcd, grd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Export Heights to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yaml Params\n",
    "df = pd.DataFrame(coords_hs, columns=[\"x\",\"y\",\"h\",\"index\"])\n",
    "df.to_csv(csvOut)\n",
    "\n",
    "# Sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Calculate total time taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time Taken:  126.55844140052795\n"
     ]
    }
   ],
   "source": [
    "end = time.time()\n",
    "print(\"Total Time Taken: \", end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Draw height on image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def draw_height_on_coord(img, x_y_h:np.ndarray, on_left:str=\"tape\"): #(xc,yc,confidence,label)\n",
    "    img = img.copy()\n",
    "    if not x_y_h.size:\n",
    "        return img\n",
    "    red = (255,0,0)\n",
    "    color = red\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    for stuff in x_y_h:\n",
    "        x,y,h,index = int(stuff[0]), int(stuff[1]), stuff[2], stuff[3]\n",
    "        img = cv2.circle(img,(x,y), 1, color,5)\n",
    "        img = cv2.putText(img, f\"{h:.1f}\", (x,y),font, 0.7,red,2,cv2.LINE_AA)\n",
    "        img = cv2.putText(img, f\"{int(index)}\", (x-16,y-20),font, 0.7,red,2,cv2.LINE_AA)\n",
    "    # Writing image name\n",
    "    img = cv2.putText(img, on_left, (50,50), font, 2, red, 2, cv2.LINE_AA)\n",
    "    return img\n",
    "\n",
    "new_pd = np.asarray([df.x, df.y, df.h, df.index]).transpose()\n",
    "new_pd = scale_coord(new_pd, (1/topViewStepsize, 1/topViewStepsize), (-xmin/topViewStepsize,ymax/topViewStepsize))\n",
    "img_lidar = draw_height_on_coord(non_ground_img, new_pd, f\"Lidar {pcd_name}\")\n",
    "\n",
    "\n",
    "cv2.imwrite(f\"{topViewOut}/{pcd_name}_lidar.png\", img_lidar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0049a2b3bc9172676984e1a6f9e111534b6aee47bf78996c6631af5a4003df75"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('yolov5')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
